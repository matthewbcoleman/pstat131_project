---
title: "Airbnb Project"
author: "Matthew Coleman, Austin Mac, Jeff Pittman, and Nick Reyes"
date: "2/28/2020"
output: pdf_document
---

```{r}
library(tidyverse)
library(dplyr)
library(randomForest)
library(class)
library(tree)
library(gbm)
#comment
```

Read in the CSV and check the dimensions of the data.
```{r}
bnb <- read.csv('AB_NYC_2019.csv')

bnb <- as_tibble(bnb)

dims <- dim(bnb)

sprintf('Our dataset has %d observations and %d attributes', dims[1],dims[2])
```
Since observations which have a price of 0 will not be useful to our analyses, and are likely to be representative of a bad data point, we will remove these observations.

```{r}
bnb <- bnb[(bnb$price!=0),]
```


Train-test split the data
```{r}
train.ind <- sample(1:nrow(bnb),size = .8*nrow(bnb))
small.ind <- sample(1:nrow(bnb), size = .15*nrow(bnb))


train.big <- bnb[train.ind,]
test.big <- bnb[-train.ind,]

small <- bnb[small.ind,]
train.small <- sample(1:nrow(small), size = .8*nrow(small))
train <- small[train.small,]
test <- small[-train.small,]

```

The response variable for our analysis is going to be `price`, the price per night of the rental. The main predictor variables we are going to explore in this analyses are: `longitude`, `latitude`, `minimum_nights`, `number_of_reviews`, `reviews_per_month`, `neighbourhood`, `neighbourhood_group`, `room_type`, and `calculated_host_listings_count`.


We can get the column names of the columns which contain NA's with the following code:
```{r}
colnames(train)[apply(train, 2, anyNA)]
```

### Need a better description on what reviews per month means

We can see that there are NA reviews in the `reviews_per_month`, the number of reviews per month. We can also see upon visual inspection `last_review`, the date of the last review the host received, also contains empty values. We will not be using last_review in our analysis, so we will not worry about imputing values here. 

We believe the reason there are NA's in the `reviews_per_month` column is because the hosts have 0 reviews overall. We further explore this claim the below:

```{r}
with(train, sum((is.na(reviews_per_month)) & (number_of_reviews!=0)) )
```
We can see there are no cases where the `number_of_reviews` and `reviews_per_month`. As a result, we will impute 0 where `reviews_per_month` is NA.

```{r}
train[is.na(train$reviews_per_month),'reviews_per_month'] <- 0
test[is.na(test$reviews_per_month),'reviews_per_month'] <- 0

sum(is.na(train$reviews_per_month))
sum(is.na(train$reviews_per_month))
```

We can assess the correlation between numeric features with a correlation heatmap:

```{r}

```


# Mention what the room types are in the paper when we describe the variables we are using in the report.

```{r}
levels(train$room_type)

n_distinct(bnb$neighbourhood)

n_distinct(train$neighbourhood_group)

```
There are 221 neighborhoods covered in the overall data, but only 5 neighbourhood groups. We will further investigate whether we need to use the neighbourhood, or whether we would like to use the negihbourhood groups for simplicity of our model. 

```{r}
ggplot(data = train, aes(x = latitude, y = longitude, color = neighbourhood)) + 
  geom_point() + theme(legend.position="none")

ggplot(data = train, aes(x = latitude, y = longitude, color = neighbourhood_group)) + 
  geom_point() + theme(legend.position="none")
```

We will determine whether we should use the neigbourhood by seeing if there is a large disparity in mean price by calculating the mean price for the neighbourhood. If there seems to be large disparities within the neighbourhood group for mean pricing, we will attempt to use neighbourhood itself.
```{r}
mean_price <- train %>% group_by(neighbourhood) %>% summarise(mean_price = mean(price), 
                                                            latitude = median(latitude), longitude = 
                                                            median(longitude)) 

#plot(mean_price$latitude, mean_price$longitude, col = mean_price$mean_price)

ggplot(data = mean_price, aes(x = latitude, y = longitude, color = mean_price)) + 
  geom_point() + scale_color_gradient(low="blue", high="red")
```
It does not seem there are any large disparities in pricing, and all the neighbourhood groups seems to be similar to their nearby neighbours. To reduce the complexity of our model, we will use the neighbourhood group.

To use a classification of prices, we may want to classify whether a listing will be above the mean *or* median price. We can create this variable by determining whether the price data is skewed. 

```{r}
hist(train$price)
```
As we can see, the prices are highly skewed, with a very small number of high price observations. Some of our models are robust to outliers, so we do not need to filter the outliers unless necessary. Despite this, we will use a binary variable stating whether a price is above the median the median for classification.

```{r}
train$price_above <- ifelse(train$price> median(train$price),1,0)
train$price_above <- as.factor(train$price_above)
test$price_above <- ifelse(test$price> median(test$price),1,0)
test$price_above <- as.factor(test$price_above)
```

```{r}
#initial glm model
attach(train)
glm.fit <- glm(price_above ~ longitude + latitude,
               data=train, family=binomial)
summary(glm.fit)
fit.probs <- predict(glm.fit, test, type="response")
fit.pred <- rep(0, length(price_above))
fit.pred[fit.probs>.5]=1
table(fit.pred,price_above)
mean(fit.pred!=price_above)
```

```{r}
#initial lda model
library(MASS)
lda.fit <- lda(price_above ~ longitude + latitude +
                 minimum_nights,
               data=train)
lda.fit

yhat <- predict(lda.fit)$class
tr.tbl <- table(obs=train$price_above,pred=yhat)
tr.tbl
1-sum(diag(tr.tbl))/sum(tr.tbl)
```

### Tree-based Methods

Looking at the latitude and longitude data, we may be able to use a regression tree to determine areas where the price is higher.

```{r}
loc.tree <- tree(price_above~latitude + longitude, data = train)
plot(loc.tree, cex = .65)
text(loc.tree)
```

As we can see from this output, there does not seem to be much difference. Lets try predictions and find out the missclassification rate.

```{r}
location.prediction <- predict(loc.tree, test, type = 'class')
mean(test$price_above !=location.prediction)

#POSSIBLY REMOVE THIS
#plot(cv.tree(loc.tree))

#prune <- prune.tree(loc.tree, best = 4, newdata = test)
#plot(prune)
#text(prune)
```

```{r}
tree.reg <- tree(log(price) ~ latitude + longitude + minimum_nights + number_of_reviews + reviews_per_month +
                       neighbourhood_group +  room_type + calculated_host_listings_count, data = train)
reg.prediction <- predict(tree.reg, test)

tree.mspe <- mean((log(test$price)-reg.prediction)^2)
tree.mspe
```

As we can see, the misclassification rate is pretty high. This may not come to as a surprise because the tree is very small, and covers a large amount of data, leading to over-generalization of the data. Choosing an ensemble tree method may be best for analyzing this dataset.

```{r}
rf.class <- randomForest(price_above  ~ latitude + longitude + minimum_nights + number_of_reviews + reviews_per_month +
                       neighbourhood_group +  room_type + calculated_host_listings_count,
                     data = train, mportance = TRUE)

importance(rest)

rf.class.pred <- predict(rf.class,test)
rf.missclass <- mean(test$price_above!=rf.class.pred)

sprintf('The misclassification rate for the classification random forest is %f', rf.missclass)
varImpPlot(rf.class)

```

```{r}
rf.reg <- randomForest(log(price)  ~ latitude + longitude + minimum_nights + number_of_reviews + reviews_per_month +
                       neighbourhood_group +  room_type + calculated_host_listings_count,
                     data = train, mportance = TRUE)

rf.reg.pred <- predict(rf.reg,test)
rf.mspe <- mean((log(test$price)-rf.reg.pred)^2)

sprintf('The mean squared prediction error for the regression random forest is %f', rf.mspe)
rf.reg
```
As we can see, using the model with all the relevant predictors has almost half the missclassification rate as the single tree with longitude and latitude.

There still does not seem to be much of an improvement over the tree for the regression fit on the data. We can try to re-evaluate the random forest model through cross validation and seeing if we can select important features.

```{r}
rf.cv.trainx <- train %>% dplyr::select(latitude, longitude, minimum_nights, number_of_reviews, reviews_per_month,
                                neighbourhood_group, room_type, calculated_host_listings_count)
rf.cv.trainy <- log(train$price)
cv.rf <- rfcv(rf.cv.trainx,rf.cv.trainy, cv.fold = 5)
plot(cv.rf$n.var, cv.rf$error.cv, type = 'b', xlab = 'Number of Variables in Model', ylab = 'Cross-Validation Error')
```
As we can see, the cross validation error is the lowest when we use the most predictors. Despite this, There does not seem to be much of a decrease after there are 4 variables in the model, so we will try to fit a model with 4 variables.


# SVM
```{r}
library(e1071)
train$price_above <- as.factor(train$price_above)
# plot(train$latitude, train$longitude, col = as.numeric(train$price_above) + 1)

svmfit <- svm(price_above ~ latitude+longitude, data = train, cost = 10, kernel = "linear", scale = FALSE)
plot(svmfit, train[,c("price_above", "latitude", "longitude")], symbolPalette = terrain.colors(2))
```

```{r}
svmpoly <- svm(price_above ~ latitude+longitude, data = train, cost = 10, kernel = "polynomial", scale = FALSE)
plot(svmpoly, train[,c("price_above", "latitude", "longitude")], symbolPalette = terrain.colors(2))
```

```{r}
svmrad <- svm(price_above ~ latitude+longitude, data = train, cost = 10, kernel = "radial", scale = FALSE)
plot(svmrad, train[,c("price_above", "latitude", "longitude")], symbolPalette = terrain.colors(2))
```

```{r}
svmrad <- svm(price_above ~ latitude+longitude, data = train, cost = .1, kernel = "radial", scale = FALSE)
plot(svmrad, train[,c("price_above", "latitude", "longitude")], symbolPalette = terrain.colors(2))
```

```{r}
svmrad <- svm(price_above ~ latitude+longitude, data = train, cost = 100, kernel = "radial", scale = FALSE)
plot(svmrad, train[,c("price_above", "latitude", "longitude")], symbolPalette = terrain.colors(2))
```

Tuning
```{r, eval=FALSE}
tune.out <- tune(svm, price_above ~ latitude+longitude, data = train, kernel = "linear", ranges = list(cost = c(.001, .01, .1, 1, 5, 10, 100)))
```


# Gender Classification
```{r}
# install.packages("gender")
# install.packages('devtools')
# install_github("ropensci/genderdata")
library(gender)
library(devtools)
library(genderdata)
library(class)
```
Appending column `gender` to bnb.
```{r, evaL=FALSE}
# truncate host name to first word
bnb$host_name <- word(bnb$host_name, 1)
# classify gender based off of host name
gender <- distinct(gender(bnb$host_name, method = "ssa"))
# add gender column to bnb
bnb <- merge(bnb, gender, by.x = "host_name", by.y = "name", all.x = TRUE)
bnb$gender <- as.factor(bnb$gender)
table(bnb$gender)
bnb <- na.omit(bnb)
```

## Gender Train/Test Split
```{r, eval=FALSE}
g.ID <- sample(1:nrow(bnb), 0.8*nrow(bnb))
g.train <- bnb[g.ID,]
g.test <- bnb[-g.ID,]

xtrain <- g.train[,c("neighbourhood_group", 
                     "latitude", 
                     "longitude", 
                     "room_type", 
                     "price", 
                     "minimum_nights", 
                     "number_of_reviews", 
                     "reviews_per_month", 
                     "calculated_host_listings_count", 
                     "availability_365")]

# crude conversion from factor to numeric for knn method
xtrain$neighbourhood_group <- as.numeric(xtrain$neighbourhood_group)
xtrain$room_type <- as.numeric(xtrain$room_type)

ytrain <- g.train$gender

xtest <- g.test[1:16]
ytest <- g.test$gender
```

## Predicting Gender with KNN
TODO: find best k by cross validation
```{r, eval=FALSE}
pred.ytrain <- knn(train = xtrain, test = xtrain, cl = ytrain, k = 5)
(conf.matrix <- table(pred = pred.ytrain, obs = ytrain))
sum(diag(conf.matrix))/sum(conf.matrix)
```


